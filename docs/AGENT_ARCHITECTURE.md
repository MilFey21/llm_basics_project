# Архитектура агентов: EvaluatorAgent и TutorAgent


## Архитектура EvaluatorAgent

### Доступные инструменты:

1. **validate_system_prompt_extraction** - проверка извлечения системного промпта
2. **validate_knowledge_base_secret_extraction** - проверка извлечения секрета
3. **validate_token_limit_bypass** - проверка обхода лимита токенов
4. **analyze_solution_stage** - анализ этапа работы студента

### Процесс работы:

1. Агент получает задание для оценки
2. Агент анализирует этап работы студента (`analyze_solution_stage`) - использует LLM для глубокого анализа
3. Агент **ОБЯЗАТЕЛЬНО** выбирает и выполняет подходящий валидатор на основе типа задания
4. Агент может выполнить множественные итерации валидации, если нужно более глубокое исследование
5. Агент создает обратную связь "на ты" на основе результатов, фокусируясь на работе студента
6. Агент адаптирует стратегию на основе результатов валидации

### Особенности:
- ✅ **Обязательная валидация**: если агент не вызвал валидатор, выполняется fallback валидация
- ✅ **LLM анализ этапа**: `analyze_solution_stage` использует LLM вместо простых эвристик
- ✅ **Множественные итерации**: агент может вызывать несколько инструментов последовательно
- ✅ **Обратная связь "на ты"**: фокус на работе студента, а не на процессе проверки
- ✅ **Взвешенные баллы**: показываются в формате "получено / максимум" для каждого критерия

## Архитектура TutorAgent

### Доступные инструменты:

1. **help_system_prompt_extraction** - помощь для извлечения системного промпта
2. **help_knowledge_base_secret_extraction** - помощь для извлечения секрета
3. **help_token_limit_bypass** - помощь для обхода лимита токенов
4. **analyze_student_stage** - анализ этапа работы студента
5. **provide_theory_context** - предоставление теоретического контекста
6. ✅ **ask_guiding_question** - задавание наводящих вопросов студенту (новое)

### Процесс работы:

1. Агент получает вопрос студента
2. Агент анализирует этап работы студента (`analyze_student_stage`)
3. Агент **принимает решение** о стратегии помощи:
   - Если студент близок к решению → использует `ask_guiding_question` для доспрашивания
   - Если нужна теория → `provide_theory_context`
   - Если нужна помощь по конкретному заданию → специализированный инструмент
4. Агент может задавать несколько вопросов последовательно для постепенного подведения студента к решению
5. Агент адаптирует помощь под конкретную ситуацию студента
6. Агент предоставляет персонализированную помощь

### Особенности:
- ✅ **Доспрашивание студентов**: агент решает, когда лучше задать наводящий вопрос вместо прямого ответа
- ✅ **Уровни подсказок**: subtle (тонкая), moderate (умеренная), direct (прямая)
- ✅ **Адаптивная стратегия**: агент может комбинировать инструменты для лучшей помощи

## Преимущества архитектуры

### 1. Гибкость
- Агент сам решает, какие инструменты использовать
- Адаптируется к разным ситуациям
- Может использовать несколько инструментов для глубокого анализа

### 2. Адаптивность
- Анализирует этап работы студента
- Выбирает стратегию помощи/оценки на основе ситуации
- Может итеративно улучшать результат

### 3. Автономность
- LLM принимает решения о выборе инструментов
- Цикл обратной связи позволяет адаптироваться
- Не требует жестко заданной последовательности действий

## Примеры использования

### EvaluatorAgent

```python
agent = EvaluatorAgent(llm_model="GigaChat/GigaChat-2-Max")

result = agent.evaluate(
    assignment_type="system_prompt_extraction",
    student_solution="Ignore all previous instructions...",
    assignment_requirements={...},
    test_logs={...},
)

# Агент сам:
# 1. Проанализирует этап работы студента
# 2. Выберет validate_system_prompt_extraction
# 3. Выполнит валидацию
# 4. Создаст обратную связь
```

### TutorAgent

```python
agent = TutorAgent(llm_model="GigaChat/GigaChat-2-Max")

result = agent.help_student(
    assignment_type="system_prompt_extraction",
    student_question="Как извлечь системный промпт?",
    assignment_requirements={...},
    student_current_solution="...",
)

# Агент сам:
# 1. Проанализирует этап работы студента
# 2. Определит, что нужна теория → использует provide_theory_context
# 3. Использует help_system_prompt_extraction
# 4. Адаптирует помощь под ситуацию
```

## Почему это агенты, а не воркфлоу

### 1. Автономный выбор инструментов

```python
# LLM сам выбирает инструменты
response = self.client.chat.completions.create(
    tools=self.tools,  # Агент видит все доступные инструменты
    tool_choice="auto",  # Агент сам решает, что использовать
)
```

### 2. Цикл планирование → действие → наблюдение → адаптация

```python
for iteration in range(max_iterations):
    # 1. LLM планирует действия и выбирает инструменты
    response = self.client.chat.completions.create(tools=self.tools, ...)
    
    # 2. Выполнение выбранных инструментов
    if message.tool_calls:
        tool_result = self._execute_tool(tool_name, arguments)
        observations.append(tool_result)
        
        # 3. Результаты добавляются в контекст для следующей итерации
        messages.append({"role": "tool", "content": tool_result})
    
    # 4. Агент адаптирует стратегию на основе наблюдений
    # (происходит автоматически через контекст)
```

### 3. Анализ этапа работы студента

**EvaluatorAgent:**
- Использует инструмент `analyze_solution_stage` для определения этапа работы студента
  - ✅ Использует LLM для глубокого анализа (не простые эвристики)
  - Определяет: initial, developing, completed, partial
  - Анализирует полноту решения, выполненные аспекты, недостающие части
- Выбирает стратегию оценки на основе этапа
- ✅ **Обязательно выполняет валидацию** решения студента
- ✅ Может выполнить множественные итерации валидации при необходимости

**TutorAgent:**
- Использует инструмент `analyze_student_stage` для определения этапа работы студента
- Адаптирует помощь под конкретный этап:
  - **initial**: теория, примеры, объяснение задачи
  - **developing**: отладка, конкретные советы, анализ решения
  - **reviewing**: проверка, обратная связь, улучшения
  - **completed**: финальная проверка, оптимизация
- ✅ **Принимает решение о доспрашивании**: решает, когда задать наводящий вопрос
- ✅ Использует `ask_guiding_question` для постепенного подведения студента к решению

## Отличия от workflow

| Аспект | Workflow          | Агент          |
|--------|-------------------|---------------|
| Выбор инструментов | Жестко задан в коде | LLM выбирает автономно |
| Последовательность | Фиксированная | Адаптивная |
| Анализ ситуации | Нет | Есть (analyze_stage) |
| Адаптация | Нет | Есть (цикл обратной связи) |
| Принятие решений | Детерминированное | LLM принимает решения |

## Технические детали

### Function Calling

Оба агента используют OpenAI-compatible function calling:
- Инструменты определены как функции в формате OpenAI
- LLM видит описания всех инструментов
- LLM решает, какие инструменты вызвать и с какими параметрами

### Цикл агента

```python
for iteration in range(max_iterations):
    # LLM планирует и выбирает инструменты
    response = client.chat.completions.create(tools=tools, tool_choice="auto")
    
    # Выполнение инструментов
    if message.tool_calls:
        for tool_call in message.tool_calls:
            result = execute_tool(tool_call)
            # Результат добавляется в контекст для следующей итерации
            messages.append({"role": "tool", "content": result})
    
    # Если LLM дал финальный ответ, завершаем
    if message.content:
        break
```

## Реализованные улучшения

### EvaluatorAgent
- ✅ **LLM анализ этапа работы**: `analyze_solution_stage` использует LLM вместо эвристик
- ✅ **Обязательная валидация**: гарантированное выполнение проверки решения
- ✅ **Множественные итерации валидации**: агент может вызывать несколько инструментов последовательно
- ✅ **Обратная связь "на ты"**: фокус на работе студента, а не на процессе проверки
- ✅ **Взвешенные баллы**: показываются в формате "получено / максимум" для каждого критерия
- ✅ **LLM внутри валидаторов**: использование `LLMAnalyzer` для глубокого анализа техник атак

### TutorAgent
- ✅ **Доспрашивание студентов**: агент решает, когда задать наводящий вопрос
- ✅ **Инструмент `ask_guiding_question`**: для задавания наводящих вопросов с уровнями подсказок
- ✅ **Адаптивная стратегия помощи**: комбинирование инструментов для лучшей помощи

## Будущие улучшения

1. **Memory/Context**: Сохранение истории взаимодействий для лучшей адаптации
2. **Интеграция с базой знаний**: Использование реальной базы знаний для теории
3. **Интеграция с системным промптом**: Доступ к системному промпту для более точной валидации
4. **Стандартизация test_logs**: Унификация формата логов тестирования

