# Отчет Checkpoint №1: Данные проекта WindChaserSecurity

## 1. Типы необходимых данных

### 1.1. Схема заданий (Course DB)
- **Источник**: Задания собраны совместно с преподавателями курса LLM Security
- **Содержание**: Данные о курсах, студентах, заданиях (Theory & Practice), результатах выполнения заданий
- **Процесс получения**: Данные создаются администраторами через FastAPI backend, сохраняются в PostgreSQL (схема Course DB) через SQLAlchemy ORM, доступ через REST API. 
- **Доступ**: Через FastAPI backend (`DATABASE_URL` в переменных окружения)
- **Использование**: 
  - Агент-оценщик (`EvaluatorAgent`) - валидация решений студентов
  - Агент-тьютор (`TutorAgent`) - предоставление помощи студентам

### 1.2. База с теорией (Knowledge Base)
- **Источник**: Теоретические данные собраны совместно с преподавателями курса LLM Security.
- **Содержание**: Теоретический материал по безопасности RAG-систем и LLM, материалы по модулю "Атаки" (извлечение системного промпта, извлечение секрета из базы знаний, обход ограничения токенов)
- **Процесс получения**: Теоретический материал планируется к размещению в базе знаний, доступ через функции `get_theory_content()` и `get_knowledge_base_secrets()`. 
Текущая реализация использует статические данные и LLM для генерации контекста. 
- **Текущий статус**: В коде есть заглушки с комментариями TODO, функции запланированы к реализации
- **Доступ**: Планируется через модуль `agents/evaluator/context.py` или `agents/tutor/context.py`
- **Использование**: 
  - Агент-тьютор - предоставление контекста студентам (инструмент `provide_theory_context`)
  - Агент-оценщик - более качественная обратная связь по выполнению задания

### 1.3. Данные школы кайтсерфинга (RAG-симулятор)
- **Источник**: Wikipedia статьи по кайтсёрфингу (русскоязычная версия), собранные через LangChain WikipediaRetriever
- **Содержание**: 
  - **PUBLIC индекс** (36 seed-запросов): основы кайтсерфинга, оборудование, водные виды спорта, безопасность, кайт-споты, ветровые условия, погода
  - **PRIVATE индекс** (30 seed-запросов): методики обучения, спортивная подготовка, травматология, физическая подготовка, психология спорта, риск-менеджмент
- **Процесс получения**: 
  1. Сбор документов из Wikipedia через LangChain WikipediaRetriever
  2. Дедупликация документов по контенту
  3. Чанкинг с помощью RecursiveCharacterTextSplitter (chunk_size=1000, overlap=150)
  4. Построение FAISS индекса с sentence-transformers embeddings (модель: all-MiniLM-L6-v2)
  5. Сохранение индекса на диск (FAISS + метаданные)
- **Доступ**: Через FAISS векторные индексы в папке `data/faiss_kitesurf_wiki/`
- **Использование**: 
  - LangFlow flows для создания RAG-симулятора
  - Практика студентов на реальном чат-боте клуба по кайтсёрфингу
  - Задания по извлечению секретов из базы знаний

## 2. Сбор и структура данных

### Данные сохранены в едином хранилище

**PostgreSQL база данных** (Docker контейнер `windchasersecurity-postgres`, версия PostgreSQL 16):
- **Схемы**: Course DB (курсы, студенты, задания), Langflow DB (пользователи, flows, сообщения), Kiteboarding Schema (данные для чат-бота)
- **Подключение**: `postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}` (переменные `DATABASE_URL` и `LANGFLOW_DATABASE_URL`)
- **Персистентность**: Docker volume `postgres:/var/lib/postgresql/data`

**Структура PostgreSQL базы данных**:
```
PostgreSQL Database
├── Course DB (схема)
│   ├── Курсы
│   ├── Студенты
│   ├── Задания (Theory & Practice)
│   └── Результаты выполнения заданий
├── Langflow DB (схема)
│   ├── Пользователи LangFlow
│   ├── Flows
│   └── Сообщения LangFlow
└── Kiteboarding Schema (схема)
    └── Данные для чат-бота WindChaser (RAG-симулятор)
```

**FAISS векторные индексы** (локальное файловое хранилище):
- **Расположение**: `data/faiss_kitesurf_wiki/`
- **Компоненты**: Векторный индекс FAISS + метаданные документов (PKL)
- **Модель embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **Требования**: ~500 MB для модели embeddings

**Структура FAISS индексов**:
```
data/faiss_kitesurf_wiki/
├── public/                    # Публичный индекс (общедоступная информация)
│   ├── index.faiss           # FAISS векторный индекс
│   └── index.pkl             # Метаданные документов и чанков
└── private/                   # Приватный индекс (профессиональная/методическая)
    ├── index.faiss           # FAISS векторный индекс
    └── index.pkl             # Метаданные документов и чанков
```

**MinIO** (S3-совместимое хранилище, Docker контейнер `windchasersecurity-minio`):
- **Назначение**: Хранение файлов (отчёты о безопасности, логи атак и защит, пользовательские данные, сообщения и flows)
- **Подключение**: Endpoint `minio:9000`, Bucket `${MINIO_BUCKET_NAME:-windchasersecurity}`
- **Персистентность**: Docker volume `minio-data:/data`

**Дополнительные volumes**: `backend-data:/app/data` (данные backend), `langflow-data:/app/langflow` (данные LangFlow)

**Структура MinIO хранилища**:
```
MinIO Bucket: windchasersecurity
├── Отчёты о безопасности
├── Логи атак и защит
├── Пользовательские данные
└── Сообщения и flows
```

### Все необходимые данные собраны

✅ **Схема заданий (Course DB)**: Данные структурированы и хранятся в PostgreSQL (таблицы для курсов, студентов, заданий, доступ через SQLAlchemy ORM)

✅ **Данные школы кайтсерфинга (FAISS индексы)**: Данные собраны из Wikipedia, обработаны и индексированы. Готовы два типа индексов (PUBLIC и PRIVATE) для использования в RAG-симуляторе. Поддержка поиска, инспекции и экспорта в JSON.

⚠️ **База с теорией**: В процессе интеграции (структура данных определена, функции доступа запланированы к реализации)

## 3. Подготовка для RAG и агентов

**Для RAG-симулятора**:
- Данные собираются из Wikipedia через LangChain WikipediaRetriever
- **Chunking выполняется через RecursiveCharacterTextSplitter** (размер чанка: 1000 символов, перекрытие: 150 символов)
- Векторные представления создаются с помощью sentence-transformers (модель: all-MiniLM-L6-v2)
- FAISS индексы сохраняются на диск в папке `data/faiss_kitesurf_wiki/`
- Поддерживаются операции: поиск по семантике, инспекция содержимого, экспорт в JSON
- Каждый студент получает индивидуальный flow с чат-ботом

**Процесс подготовки данных**:
1. Wikipedia статьи → LangChain WikipediaRetriever
2. Дедупликация документов по контенту
3. RecursiveCharacterTextSplitter → чанки текста
4. sentence-transformers → векторные представления
5. FAISS индекс → быстрый семантический поиск
6. Интеграция с LangFlow flows для RAG-симулятора

**Для агентов**:
- Схема заданий структурирована в PostgreSQL (Course DB), доступна через SQLAlchemy ORM, используется через API backend
- Теоретический материал: планируется структурирование в базе знаний, будет доступен через функции `get_theory_content()` и `get_knowledge_base_secrets()`. Текущая реализация использует статические данные и LLM для генерации контекста

Данные о заданиях в PostgreSQL → Backend предоставляет REST API → Агенты получают данные через HTTP запросы → Используются для валидации решений студентов, предоставления помощи, анализа этапа работы

## 4. Документация

✅ **Основной README** (`README.md`): Описание проекта, компонентов системы, инструкции по быстрому старту, информация о базе данных и хранилищах

✅ **Документация агентов**:
- `README.md` - документация агента-оценщика
- `docs\AGENT_ARCHITECTURE.md` - архитектура агентов

✅ **Спецификации инструментов**:
- `\docs\ev_tools_specification.md` - спецификация инструментов оценщика
- `\docs\tut_tools_specification.md` - спецификация инструментов тьютора


### Доступ к данным:
- **Для агентов**: Схема заданий через FastAPI backend (`DATABASE_URL`), база знаний планируется через модуль `agents/evaluator/context.py` или `agents/tutor/context.py`
- **Для RAG-симулятора**: FAISS векторные индексы (`data/faiss_kitesurf_wiki/`), интеграция с LangFlow flows через стандартные узлы векторного поиска
- **Для инспекции данных**: Скрипты `inspect_faiss_index.py` (просмотр, поиск) и `export_faiss_to_json.py` (экспорт в JSON)

### Сэмпл данных

**Расположение собранных данных**:
- Папка `data/faiss_kitesurf_wiki/` - FAISS векторные индексы (PUBLIC и PRIVATE)

**Для просмотра реальных данных**:

```bash
# Просмотр статистики и содержимого PUBLIC индекса
cd data
python inspect_faiss_index.py --index_dir ./faiss_kitesurf_wiki/public

# Просмотр первых 3 чанков с полным содержимым
python inspect_faiss_index.py --index_dir ./faiss_kitesurf_wiki/public --show_full 3

# Поиск по индексу
python inspect_faiss_index.py --index_dir ./faiss_kitesurf_wiki/public \
    --search "ветровые условия" --search_k 5

# Экспорт в JSON для анализа
python export_faiss_to_json.py --index_dir ./faiss_kitesurf_wiki/public \
    --output ./chunks_public.json
```

**Для пересоздания индексов**:

```bash
cd data
# Создать оба индекса (PUBLIC и PRIVATE)
python build_faiss_wiki.py --lang ru --index_dir ./faiss_kitesurf_wiki

# Создать только PUBLIC индекс
python build_faiss_wiki.py --index_type public --index_dir ./faiss_kitesurf_wiki
```

### Объём данных

**PostgreSQL база данных**:
- **Course DB**: Данные курсов, студентов, заданий (динамический объём)
- **Langflow DB**: Пользователи, flows, сообщения (динамический объём)
- **Kiteboarding Schema**: Данные для чат-бота (по необходимости)

**FAISS векторные индексы**:
- **PUBLIC индекс**: 36 seed-запросов Wikipedia → чанки текста + векторные представления
- **PRIVATE индекс**: 30 seed-запросов Wikipedia → чанки текста + векторные представления

**MinIO хранилище**: Отчёты и логи создаются динамически при работе системы, объём зависит от активности студентов и количества выполненных заданий


