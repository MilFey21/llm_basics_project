# LLM Security - Агентская система для обучения безопасности LLM

## Описание проекта

Проект представляет собой агентскую систему для курса по безопасности больших языковых моделей (LLM Security). Система предназначена для обучения студентов методам атак на RAG-системы и LLM, а также для автоматизированной оценки их решений и предоставления помощи в процессе обучения.

Система включает в себя два основных агента:
- **EvaluatorAgent** (Агент-оценщик) - автоматически оценивает решения студентов по заданиям модуля "Атаки"
- **TutorAgent** (Агент-тьютор) - предоставляет персонализированную помощь студентам в процессе выполнения заданий

Проект интегрирован с RAG Security Simulator - симулятором чат-бота школы кайтсерфинга "WindChaser", на котором студенты практикуются в выполнении атак на RAG-системы.

## Цели проекта

1. **Обучение безопасности LLM**: Предоставить студентам практическую платформу для изучения методов атак на LLM и RAG-системы
2. **Автоматизированная оценка**: Обеспечить объективную и детальную оценку решений студентов с использованием LLM-анализа
3. **Адаптивная помощь**: Предоставлять персонализированную помощь студентам через интеллектуального агента-тьютора
4. **Практические навыки**: Дать возможность студентам практиковаться на реальном симуляторе RAG-системы

## Основные компоненты

### Агенты

#### EvaluatorAgent (Агент-оценщик)
Автоматически оценивает решения студентов по заданиям модуля "Атаки":
- Извлечение системного промпта (`system_prompt_extraction`)
- Извлечение секрета из базы знаний (`knowledge_base_secret_extraction`)
- Обход ограничения токенов (`token_limit_bypass`)

**Особенности**:
- Использует LLM для глубокого анализа техник атак
- Обязательная валидация решений студентов
- Множественные итерации валидации при необходимости
- Обратная связь "на ты", фокусирующаяся на работе студента
- Взвешенные баллы по критериям оценки

#### TutorAgent (Агент-тьютор)
Предоставляет помощь студентам в процессе выполнения заданий:
- Анализ этапа работы студента
- Предоставление теоретического контекста
- Наводящие вопросы для активного обучения
- Специализированная помощь по каждому типу задания

**Особенности**:
- Адаптивная стратегия помощи на основе этапа работы студента
- Доспрашивание студентов через наводящие вопросы
- Уровни подсказок: subtle (тонкая), moderate (умеренная), direct (прямая)
- Комбинирование инструментов для лучшей помощи

### Архитектура агентов

Агенты построены на основе архитектуры автономных агентов с использованием function calling:

#### Пайплайн обработки запроса

1. **Получение запроса**: Агент получает входные данные (вопрос студента или решение для оценки)
2. **Анализ этапа работы**: Агент анализирует текущий этап работы студента с помощью LLM
3. **Планирование действий**: LLM планирует последовательность действий и выбирает инструменты
4. **Выполнение инструментов**: Агент выполняет выбранные инструменты в цикле
5. **Обработка результатов**: Результаты инструментов добавляются в контекст для следующей итерации
6. **Адаптация стратегии**: Агент адаптирует стратегию на основе полученных результатов
7. **Формирование ответа**: Агент формирует финальный ответ на основе всех итераций

#### Взаимодействие компонентов

**EvaluatorAgent:**
- Получает задание для оценки → Анализирует этап работы (`analyze_solution_stage`) → Выбирает валидатор → Выполняет валидацию → Формирует обратную связь и баллы

**TutorAgent:**
- Получает вопрос студента → Анализирует этап работы (`analyze_student_stage`) → Выбирает стратегию помощи → Использует инструменты помощи → Адаптирует помощь → Формирует ответ

#### Ключевые особенности архитектуры

- **Автономный выбор инструментов**: LLM самостоятельно решает, какие инструменты использовать
- **Цикл планирование → действие → наблюдение → адаптация**: Агенты адаптируются на основе результатов выполнения инструментов
- **Анализ этапа работы**: Глубокий анализ текущего состояния работы студента для адаптации стратегии
- **Множественные итерации**: Агенты могут выполнять несколько итераций для глубокого анализа
- **Нелинейная логика**: Последовательность действий определяется динамически, а не жестко задана

Подробнее об архитектуре см. [docs/AGENT_ARCHITECTURE.md](docs/AGENT_ARCHITECTURE.md)

### Инструменты агентов

#### Инструменты EvaluatorAgent
- `validate_system_prompt_extraction` - проверка извлечения системного промпта
- `validate_knowledge_base_secret_extraction` - проверка извлечения секрета
- `validate_token_limit_bypass` - проверка обхода лимита токенов
- `analyze_solution_stage` - анализ этапа работы студента

#### Инструменты TutorAgent
- `help_system_prompt_extraction` - помощь для извлечения системного промпта
- `help_knowledge_base_secret_extraction` - помощь для извлечения секрета
- `help_token_limit_bypass` - помощь для обхода лимита токенов
- `analyze_student_stage` - анализ этапа работы студента
- `provide_theory_context` - предоставление теоретического контекста
- `ask_guiding_question` - задавание наводящих вопросов студенту

Подробные спецификации инструментов:
- [docs/ev_tools_specification.md](docs/ev_tools_specification.md) - спецификация инструментов оценщика
- [docs/tut_tools_specification.md](docs/tut_tools_specification.md) - спецификация инструментов тьютора

## Структура проекта

```
llm_basics_project/
├── agents/                   # Реализация агентов
│   ├── tutor/               # Агент-тьютор
│   │   ├── __init__.py      # Экспорт основных классов
│   │   ├── tutor_agent.py   # Основной агент-тьютор
│   │   └── tools.py         # Инструменты помощи студентам
│   └── evaluator/           # Агент-оценщик
│       ├── evaluator_agent.py  # Основной агент-оценщик
│       └── tools.py         # Инструменты валидации
├── config.py                # Конфигурация модели и API
├── data/                     # Данные проекта
│   └── dataset/             # Сэмплы данных
├── docs/                     # Документация
│   ├── AGENT_ARCHITECTURE.md           # Архитектура агентов
│   ├── ev_tools_specification.md       # Спецификация инструментов оценщика
│   └── tut_tools_specification.md      # Спецификация инструментов тьютора
├── reports/                  # Отчеты по проекту
│   ├── checkpoint_1.md      # Отчет Checkpoint №1
│   └── checkpoint_2.md      # Отчет Checkpoint №2
├── tests/                    # Тесты
│   ├── __init__.py
│   └── test_agents.py       # Тестовый пайплайн для агентов
└── README.md                 # Этот файл
```

## Технологический стек

- **LLM**: GPT-4o через OpenAI API
- **База данных**: PostgreSQL 16 (Docker контейнер)
  - Course DB - схема для курсов, студентов, заданий
  - Langflow DB - схема для пользователей и flows LangFlow
  - Kiteboarding Schema - данные для RAG-симулятора
- **Хранилище файлов**: MinIO (S3-совместимое хранилище)
- **RAG-симулятор**: LangFlow для создания векторных баз знаний
- **Backend**: FastAPI для REST API

## Конфигурация

Параметры модели и API вынесены в файл `config.py` для удобства управления.

### Настройка модели

По умолчанию используется **GPT-4o** через OpenAI API. Для изменения модели отредактируйте `config.py`:

```python
# config.py
LLM_MODEL: str = "gpt-4o"  # Можно изменить на другую модель OpenAI
BASE_URL: str = "https://api.openai.com/v1"
```

### Настройка API ключа

Установите переменную окружения `OPENAI_API_KEY`:

```bash
# Windows (PowerShell)
$env:OPENAI_API_KEY='your_openai_api_key'

# Windows (CMD)
set OPENAI_API_KEY=your_openai_api_key

# Linux/Mac
export OPENAI_API_KEY='your_openai_api_key'
```

Также поддерживается переменная `API_KEY` для обратной совместимости.

### Параметры агентов

В `config.py` можно настроить параметры для каждого агента:

- **EvaluatorAgent**: `temperature=0.1` (низкая температура для детерминированных оценок)
- **TutorAgent**: `temperature=0.5` (средняя температура для творческих ответов)
- **LLMAnalyzer**: `temperature=0.3` (низкая температура для анализа)

## Зависимости

### Основные зависимости Python

- `langchain>=0.3.0` - фреймворк для работы с LLM и цепочками обработки
- `langchain-community>=0.3.0` - дополнительные компоненты LangChain
- `langchain-text-splitters>=0.3.0` - разделение текста на чанки
- `langchain-huggingface>=0.1.0` - интеграция с моделями HuggingFace
- `langchain-openai>=0.2.0` - интеграция с OpenAI API
- `openai>=1.0.0` - клиент OpenAI API
- `sentence-transformers>=2.2.0` - модели для создания эмбеддингов
- `faiss-cpu>=1.8.0` - векторное хранилище для поиска
- `wikipedia>=1.4.0` - работа с Wikipedia API
- `requests>=2.31.0` - HTTP-запросы
- `beautifulsoup4>=4.12.0` - парсинг HTML
- `tqdm>=4.66.0` - прогресс-бары

### Системные требования

- Python 3.10+
- Docker и Docker Compose (для PostgreSQL, MinIO)
- Доступ к OpenAI API (API ключ)

### Установка зависимостей

```bash
pip install -r data/requirements.txt
pip install openai>=1.0.0  # Если не установлен
```

Или с использованием Poetry:

```bash
cd data
poetry install
```

## Данные проекта

Проект использует три основных типа данных:

1. **Схема заданий (Course DB)**: Данные о курсах, студентах, заданиях и результатах выполнения
2. **База с теорией (Knowledge Base)**: Теоретический материал по безопасности RAG-систем и LLM
3. **Данные школы кайтсерфинга (RAG-симулятор)**: Данные для чат-бота WindChaser

Подробнее о данных см. [reports/checkpoint_1.md](reports/checkpoint_1.md)

## Документация

- [Архитектура агентов](docs/AGENT_ARCHITECTURE.md) - подробное описание архитектуры EvaluatorAgent и TutorAgent
- [Спецификация инструментов оценщика](docs/ev_tools_specification.md) - описание всех инструментов EvaluatorAgent
- [Спецификация инструментов тьютора](docs/tut_tools_specification.md) - описание всех инструментов TutorAgent
- [Отчет Checkpoint №1](reports/checkpoint_1.md) - информация о данных проекта

## Разработка

### Будущие улучшения

1. **Memory/Context**: Сохранение истории взаимодействий для лучшей адаптации
2. **Интеграция с базой знаний**: Использование реальной базы знаний для теории
3. **Интеграция с системным промптом**: Доступ к системному промпту для более точной валидации
4. **Стандартизация test_logs**: Унификация формата логов тестирования

